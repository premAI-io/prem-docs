"use strict";(self.webpackChunkprem_docs=self.webpackChunkprem_docs||[]).push([[2290],{3905:(e,t,n)=>{n.d(t,{Zo:()=>l,kt:()=>h});var r=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=r.createContext({}),p=function(e){var t=r.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},l=function(e){var t=p(e.components);return r.createElement(c.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),u=p(n),m=o,h=u["".concat(c,".").concat(m)]||u[m]||d[m]||a;return n?r.createElement(h,i(i({ref:t},l),{},{components:n})):r.createElement(h,i({ref:t},l))}));function h(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=m;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[u]="string"==typeof e?e:o,i[1]=s;for(var p=2;p<a;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},41016:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>p});var r=n(87462),o=(n(67294),n(3905));const a={id:"chat-quickstart",title:"Quick Start with LangChain",sidebar_label:"LangChain",sidebar_position:2},i="Quick Start with LangChain",s={unversionedId:"prem-app/usage/vector-store/chat-quickstart",id:"prem-app/usage/vector-store/chat-quickstart",title:"Quick Start with LangChain",description:"For what concerns Vector Stores Prem doesn't force any inrterface. We only take care of the orchestration. For this reason, you can just run the service and connect to it out of the box. The below example shows how you can use LangChain in order to connect to Redis Vector Store.",source:"@site/docs/prem-app/usage/vector-store/langchain.md",sourceDirName:"prem-app/usage/vector-store",slug:"/prem-app/usage/vector-store/chat-quickstart",permalink:"/docs/prem-app/usage/vector-store/chat-quickstart",draft:!1,editUrl:"https://github.com/premAI-io/dev-portal/blob/main/docs/prem-app/usage/vector-store/langchain.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"chat-quickstart",title:"Quick Start with LangChain",sidebar_label:"LangChain",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"APIs",permalink:"/docs/prem-app/usage/vector-store/api"},next:{title:"Diffuser",permalink:"/docs/category/diffuser"}},c={},p=[{value:"Import the necessary dependencies",id:"import-the-necessary-dependencies",level:3},{value:"Create some documents that will be indexed",id:"create-some-documents-that-will-be-indexed",level:3},{value:"Upsert",id:"upsert",level:3}],l={toc:p},u="wrapper";function d(e){let{components:t,...n}=e;return(0,o.kt)(u,(0,r.Z)({},l,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"quick-start-with-langchain"},"Quick Start with LangChain"),(0,o.kt)("p",null,"For what concerns Vector Stores Prem doesn't force any inrterface. We only take care of the orchestration. For this reason, you can just run the service and connect to it out of the box. The below example shows how you can use LangChain in order to connect to Redis Vector Store."),(0,o.kt)("h3",{id:"import-the-necessary-dependencies"},"Import the necessary dependencies"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\n!pip install redis\n\nimport os\n\nfrom langchain.chains import LLMChain\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nfrom langchain.docstore.document import Document\nfrom langchain.vectorstores.redis import Redis\nfrom langchain.prompts import PromptTemplate\n\nos.environ["OPENAI_API_KEY"] = "random-string"\n\n')),(0,o.kt)("h3",{id:"create-some-documents-that-will-be-indexed"},"Create some documents that will be indexed"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'doc1 = Document(page_content="Prem is an easy to use open source AI platform. With Prem you can quickly build provacy preserving AI applications.")\ndoc2 = Document(page_content="""\nPrem App\n\nAn intuitive desktop application designed to effortlessly deploy and self-host Open-Source AI models without exposing sensitive data to third-party.\n\n""")\ndoc3 = Document(page_content="""\nPrem Benefits\n\nEffortless Integration\nSeamlessly implement machine learning models with the user-friendly interface of OpenAI\'s API.\n\nReady for the Real World\nBypass the complexities of inference optimizations. Prem\'s got you covered.\n\nRapid Iterations, Instant Results\nDevelop, test, and deploy your models in just minutes.\n\nPrivacy Above All\nYour keys, your models. We ensure end-to-end encryption.\n\nComprehensive Documentation\nDive into our rich resources and learn how to make the most of Prem.\n\nPreserve Your Anonymity\nMake payments with Bitcoin and Cryptocurrency. It\'s a permissionless infrastructure, designed for you.\n""")\n')),(0,o.kt)("h3",{id:"upsert"},"Upsert"),(0,o.kt)("p",null,"Instantiate the necessary objects, generate the embeddings and store them into the Vector Store"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\n# Using sentence transformers all-MiniLM-L6-v2\nembeddings = OpenAIEmbeddings(openai_api_base="http://localhost:8001/v1")\n\n# Using locally running Redis\nurl = "redis://localhost:6379"\n\nrds = Redis.from_documents(docs, embeddings, redis_url=url,  index_name="prem_index_test")\n\nquery = "What are Prem Benefits?"\ndocs = vectorstore.similarity_search(query)\nprint(docs[0].page_content)\n\n')))}d.isMDXComponent=!0}}]);